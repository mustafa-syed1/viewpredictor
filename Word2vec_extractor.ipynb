{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import StringIO\n",
    "from os import listdir\n",
    "from os.path import isfile, join,isdir\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pickle as pickle\n",
    "import pandas as pd\n",
    "import gensim as gn\n",
    "import preprocessor as p\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fname=\"./geo.csv\"\n",
    "news=np.array(pd.read_csv(fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sent_stream=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"entities.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=df['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr=np.array(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38223\n"
     ]
    }
   ],
   "source": [
    "print len(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(0,len(news)):\n",
    "    temp_news=news[i][2]\n",
    "    if type(temp_news)==str:\n",
    "        temp_news=temp_news.decode(\"utf8\")\n",
    "        sentences=sent_tokenize(temp_news)\n",
    "        for sent in sentences:\n",
    "            word_tokens=word_tokenize(sent)\n",
    "            sent_stream.append(word_tokens)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_fileIn_array(filename):\n",
    "    news=np.array(pd.read_csv(filename))\n",
    "    return news\n",
    "def preprocess(s, lowercase=False):\n",
    "    s = str(s[1])\n",
    "    txt=p.clean(s)\n",
    "    txt = re.sub('[\\n]',' ',txt)\n",
    "    txt = re.sub('[:[]-_]',' ',txt)\n",
    "    return word_tokenize(txt)\n",
    "\n",
    "def tweet_classifier(filename):\n",
    "    tweets=read_fileIn_array(filename)\n",
    "    for i in range(0,len(tweets)):\n",
    "        sent_stream.append(preprocess(tweets[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp_dict=dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mypaths=arr\n",
    "i=0\n",
    "for i in range(25001,30001):\n",
    "        if mypaths[i] not in temp_dict:\n",
    "            temp_dict[mypaths[i]]=0\n",
    "        path=\"tweets/\"+ mypaths[i]+\".csv\"\n",
    "        if isfile(path):\n",
    "            tweet_classifier(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phrases=gn.models.Phrases(sent_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigram=gn.models.phrases.Phraser(phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word2vec = defaultdict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = gn.models.KeyedVectors.load_word2vec_format('./word2vec-GoogleNews-vectors/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(0,len(sent_stream)):\n",
    "    arr=bigram[sent_stream[i]]\n",
    "    for j in range(0,len(arr)):\n",
    "        word=arr[j]\n",
    "        if word in model and word not in word2vec:\n",
    "            word2vec[word] = model[word]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52589\n"
     ]
    }
   ],
   "source": [
    "print len(word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"reduced_worc2vec\", \"wb\") as output_file:\n",
    "    pickle.dump(word2vec, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del sent_stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
